{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifer from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a grasp of the theory behind logistic regression, its cost function, and parameter optimization through gradient descent (\"Logistic_Regression_Theory.ipynb\", \"Gradient_Descent_Theory.ipynb\"), we can now bundle these functions into a model. Here, we'll classify hand-written digits using the MNIST dataset, which is the \"hello world\" of classification datasets. Loading the code from the theory tutorials..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Helper function to compute the sigmoid of a given array\n",
    "    \n",
    "    input\n",
    "    -----\n",
    "    x: ndarray-like, output vector of linear function\n",
    "    \n",
    "    output\n",
    "    -----\n",
    "    s: ndarray-like, sigmoid of input\"\"\"\n",
    "    \n",
    "    sig = 1/(1+np.exp(-x))\n",
    "    return sig\n",
    "\n",
    "def init_wb(size, init_val=0):\n",
    "    \"\"\"\n",
    "    Function to initialize weights vector/bias term \n",
    "    \n",
    "    input\n",
    "    -----\n",
    "    size: int\n",
    "        length of weights vector\n",
    "    kind: int or float\n",
    "        value to init \n",
    "        \n",
    "    output\n",
    "    -----\n",
    "    w, b\n",
    "        \"\"\"\n",
    "    if init_val == 0:\n",
    "        w = np.zeros((size, 1))\n",
    "        b = 0\n",
    "    else:\n",
    "        w = np.ones((size, 1)) * init_val\n",
    "        b = init_val\n",
    "    return w, b\n",
    "\n",
    "def propagation(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Compute resulting cost function and gradients from\n",
    "    forward propagation and backward propagation respectively\n",
    "    \n",
    "    input\n",
    "    -----\n",
    "    X: ndarray-like, training set to fit\n",
    "    y: vector-like, X's corresponding target\n",
    "    w: weight vector\n",
    "    b: bias term\n",
    "    \n",
    "    output\n",
    "    ------\n",
    "    tuple; dw, db, cost\n",
    "        dw: numeric, gradient of the weight vector\n",
    "        db: numeric, gradient of the bias vector\n",
    "        cost: vector-like, cost of weight, bias terms\n",
    "    \"\"\"\n",
    "    \n",
    "    samples = X.shape[1]\n",
    "    \n",
    "    # Forward Propagation (left to right)\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    cost = -(1/samples) * np.sum(y * np.log(A) + (1 - y)*(np.log(1 - A)))\n",
    "    \n",
    "    # Backward Propagation (right to left)\n",
    "    dw = (1/samples) * np.dot(X, (A - y).T)\n",
    "    db = (1/samples) * np.sum(A - y)\n",
    "    return {'dw': dw, 'db': db, 'cost':np.squeeze(cost)}\n",
    "\n",
    "def grad_descent(X, y, w, b, n, eta):\n",
    "    \"\"\"\n",
    "    Function running gradient descent to optimize w and b\n",
    "    to minimize the cost function\n",
    "\n",
    "    input\n",
    "    -----\n",
    "    X: ndarray-like, training set to fit\n",
    "    y: vector-like, X's corresponding target\n",
    "    w: weight vector\n",
    "    b: bias term\n",
    "    n: number of iterations to loop\n",
    "    eta: learning rate\n",
    "    \n",
    "    output\n",
    "    ------\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        prop = propagation(X, y, w, b)\n",
    "        dw, db, cost = prop['dw'], prop['db'], prop['cost']\n",
    "        \n",
    "        w  = w - (eta * dw)\n",
    "        b = b - (eta * db)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    \n",
    "    return {'w':w, 'dw':dw, 'b':b, 'db':db, 'costs':costs}\n",
    "\n",
    "def prediction(X, w, b):\n",
    "    \"\"\"\n",
    "    Predict binomial classification based on trained w, b\n",
    "    \n",
    "    input\n",
    "    -----\n",
    "    w: ndarray-like\n",
    "        weights vector\n",
    "    b: int or float\n",
    "        bias term\n",
    "    X: ndarray-like\n",
    "    \n",
    "    output\n",
    "    -----\n",
    "    y_pred: np.array\n",
    "        array of predictions to corresponding X instances\n",
    "        \"\"\"\n",
    "    samples = X.shape[1]\n",
    "    y_pred = np.zeros((1, samples))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        # Bin probabiliites into actual predictions\n",
    "        y_prob = A[0, i]\n",
    "        if y_prob > 0.5:\n",
    "            y_pred[:, i] = 1\n",
    "        else:\n",
    "            y_pred[:, i] = 0\n",
    "            \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "Rather than build our own framework for our model, scikit-learn offers base classes and mixins for building custom models. This gives us the added benefit of harnessing the package's scoring and cross-validation features.\n",
    "\n",
    "If the below code looks foreign to you, you may want to review the OOP tutorials to explain the inheritance/polymorphism inherent to using base classes, and overwriting the score function.\n",
    "\n",
    "If sklearn is unfamiliar, it is a very popular machine learning framework maintained by a large community of ML developers. For our scope, there's a few simple features we'll be using that are consistent across most all of sklearn's ML algorithms. \n",
    "1. Each algorithm is passed hyperparameters to its constructor\n",
    "2. After instantiation, the model fits the data by passing training data to its `fit()` method\n",
    "3. The `predict()` method returns the predicted value when passed input data, given that the model has been trained\n",
    "4. The `score()` method compares predicted values against true values, and is used in sklearn's cross validation functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class CustomLogReg(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, init_params=0, n_iterations=100, eta=0.05):\n",
    "        self.init_params = init_params\n",
    "        self.n_iterations = n_iterations\n",
    "        self.eta = eta\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self._w, self._b = init_wb(X.shape[0], init_val=self.init_params)\n",
    "        gd = grad_descent(X, y, self._w, self._b, self.n_iterations, self.eta)\n",
    "        self.w_ = gd['w']\n",
    "        self.b_ = gd['b']\n",
    "        self.dw_ = gd['dw']\n",
    "        self.db_ = gd['db']\n",
    "        self.cost_ = gd['costs']\n",
    "        \n",
    "    def predict(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, 'w_')\n",
    "            getattr(self, 'w_')\n",
    "        except:\n",
    "            raise RuntimeError('Train classifier using .fit() before running .predict()')\n",
    "            \n",
    "        return prediction(X, self.w_, self.b_)\n",
    "    \n",
    "    def score(self, X, y_true=None):\n",
    "        \n",
    "        return((self.predict(X) == y_true).sum()) / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model on the **right data** is equally as important as how we build the model, and this step in an ML project can be highly time consuming. From a statistical standpoint, effective sampling of data is critical to the model's future ability to generalize to unseen data. For our purposes, we'll skip this step in the workflow, and use sklearn's `datasets` class to load pre-cleaned, pre-sampled MNIST data.\n",
    "\n",
    "At this step, it is also important to set aside a fraction of the data (~20% in this case) for validating the model. We'll use the larger portion for training, and see how well the model generalizes to the unseen data. No data snooping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "mnist = load_digits()\n",
    "\n",
    "X = mnist.data\n",
    "\n",
    "# Since LR is binomial and not multiclass,\n",
    "# will encode 5's as 1's and all others 0's\n",
    "y = np.array([1 if j==5 else 0 for j in mnist.target]).T\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we instantiate the classifier\n",
    "clf = CustomLogReg(n_iterations=2000, eta=0.05)\n",
    "\n",
    "# Here we fit the model\n",
    "clf.fit(X_train.T, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how our gradient descent algorithm performed in terms of our cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(np.arange(1, len(clf.cost_) + 1), clf.cost_)\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('n-iters * 100');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty quick convergence on the minimum! If we were to continue to iterate on building this model, we could throttle back on the descent iterations to save time.\n",
    "\n",
    "Now let's see how our model performs on predicting the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992576095025983"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train.T, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Near perfect score, but this alone is actually not a good measure of a machine learning algorithm. Ultimately, these models aren't valuable until they can accurately predict the target from *unseen* data. In linear models especially, overfitting can prevent generalization to new data. Let's see how the model performs on our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888888888888889"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test.T, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! >98% accuracy! This model is good to go. But in the real world, especially in image recognition, data won't be as structured as the MNIST dataset. Say we were to get poor scores on unseen data, but high scores on training data, our model is overfitting. In that case, our next step would be to add regularization to the linear model $z$, which penalizes such overfitting.\n",
    "\n",
    "We have a model now that can predict whether a hand written digit is five. Let's bundle this into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "notfive = mnist.images[y == 0][0]\n",
    "five = mnist.images[y == 1][1]\n",
    "axes[0].matshow(notfive)\n",
    "axes[1].matshow(five);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gimme_five(img):\n",
    "    \"\"\"\n",
    "    Function to classify image of handwritten\n",
    "    digit as five or not-five\n",
    "    \"\"\"\n",
    "    flatten = img.reshape(-1, 1)\n",
    "    pred = clf.predict(flatten)\n",
    "    if pred == 1:\n",
    "        return \"It's a five!\"\n",
    "    elif pred == 0:\n",
    "        return \"Not a five\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's a five!\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gimme_five(five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not a five'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gimme_five(notfive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "Now we have a fully functioning image classifier built from scratch. While this demo was done in a computer vision context, logistic regression also extends to defect analysis (pass/fail of wafers given I/O data), even in-situ endpoint capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
